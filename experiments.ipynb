{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies if not exists\n",
    "!pip3 install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34m[DEBUG, \"/usr/lib/python3.8/runpy.py\":194, in _run_module_as_main]\u001b[39m Tensorflow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "import logger \n",
    "import os\n",
    "import time\n",
    "\n",
    "logger.debug('Tensorflow version', tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceWrapper:\n",
    "    def __init__(self):\n",
    "        # configs goes here\n",
    "        self.faceWidth = 128\n",
    "        self.faceHeight = 128\n",
    "        self.batchSize = 32\n",
    "        self.datasetDir = './faces'\n",
    "\n",
    "    def importDataset(self):\n",
    "        # preprocess training data\n",
    "        train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=1./3)\n",
    "\n",
    "        # split dataset\n",
    "        train_set = train_datagen.flow_from_directory(\n",
    "            self.datasetDir,\n",
    "            seed=10,\n",
    "            target_size=(self.faceHeight, self.faceWidth),\n",
    "            class_mode='categorical', \n",
    "            batch_size=self.batchSize, \n",
    "            subset=\"training\",\n",
    "        )\n",
    "\n",
    "        test_set = train_datagen.flow_from_directory(\n",
    "            self.datasetDir,\n",
    "            seed=10,\n",
    "            target_size=(self.faceHeight, self.faceWidth),\n",
    "            class_mode='categorical', \n",
    "            batch_size=self.batchSize, \n",
    "            subset=\"validation\"\n",
    "        )\n",
    "\n",
    "        return train_set, test_set\n",
    "\n",
    "    def buildModel(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(self.faceHeight, self.faceWidth, 3)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(2, activation='softmax'),\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def runWorkFlow(self, epochs=10): # exec the whole workflow\n",
    "        train, test = self.importDataset()\n",
    "        self.model = self.buildModel()\n",
    "        logger.debug(train, test)\n",
    "        self.train(train, test, epochs=epochs)\n",
    "        \n",
    "    def train(self, train_set, test_set, epochs=10):\n",
    "        self.model.fit(\n",
    "            train_set, # data to train, a format of (X, y)\n",
    "            steps_per_epoch=len(train_set), # The number of batch iterations before a training epoch is considered finished. Ignore if whole data is load, in our case, we need this in order to iterate over batches; hence make sure that generator can generate at least: steps_per_epoch * epochs batches\n",
    "            epochs=epochs, # number of epochs, i.e times that iteration of updating weights goes\n",
    "            validation_data=test_set, # validation\n",
    "            validation_steps=len(test_set)\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    def save(self, id):\n",
    "        self.model.save(id)\n",
    "    def load(self, id):\n",
    "        self.model = keras.models.load_model(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 450 images belonging to 2 classes.\n",
      "Found 224 images belonging to 2 classes.\n",
      "\u001b[34m[DEBUG, \"/usr/lib/python3.8/runpy.py\":194, in _run_module_as_main]\u001b[39m <tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x7f128445c280> <tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x7f1278625070>\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 2.5832 - accuracy: 0.6778 - val_loss: 1.3256 - val_accuracy: 0.4955\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3328 - accuracy: 0.8800 - val_loss: 0.2841 - val_accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1900 - accuracy: 0.9467 - val_loss: 0.1819 - val_accuracy: 0.9777\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1499 - accuracy: 0.9511 - val_loss: 0.1895 - val_accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1567 - accuracy: 0.9600 - val_loss: 0.1716 - val_accuracy: 0.9420\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1143 - accuracy: 0.9644 - val_loss: 0.1145 - val_accuracy: 0.9777\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1317 - accuracy: 0.9800 - val_loss: 0.1092 - val_accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1185 - accuracy: 0.9867 - val_loss: 0.1096 - val_accuracy: 0.9598\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1055 - accuracy: 0.9756 - val_loss: 0.1044 - val_accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1281 - accuracy: 0.9911 - val_loss: 0.0958 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "face = FaceWrapper()\n",
    "\n",
    "face.runWorkFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_1 (Flatten)          (None, 49152)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 32)                1572896   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 1,572,962\nTrainable params: 1,572,962\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "face = FaceWrapper() \n",
    "face.load('fc_2cls.h5')\n",
    "print(face.model.summary())\n",
    "\n",
    "# save model\n",
    "face.save('fc_saved.h5')"
   ]
  }
 ]
}