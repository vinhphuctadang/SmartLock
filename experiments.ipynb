{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "05ece30799c2dcdac4c13b3af20453da19de8df0d9a1de52cff7e0b6e1e82bdd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies if not exists\n",
    "!pip3 install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "import logger \n",
    "import os\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_1 (Flatten)          (None, 49152)             0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 32)                1572896   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 2)                 66        \n=================================================================\nTotal params: 1,572,962\nTrainable params: 1,572,962\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "\n",
    "# naive model with fully connected\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(128,128,3)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 450 images belonging to 2 classes.\nFound 224 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "img_height = 128\n",
    "img_width  = 128\n",
    "batch_size = 32\n",
    "\n",
    "# preprocess training data\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=1/3)\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    './faces',\n",
    "    seed=10, # TODO: Change to time()\n",
    "    target_size=(128,128),\n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "test_set = train_datagen.flow_from_directory(\n",
    "    './faces',\n",
    "    seed=10, # TODO: Change to time()\n",
    "    target_size=(128,128),\n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.2320 - accuracy: 0.9667 - val_loss: 0.2786 - val_accuracy: 0.9196\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.2366 - accuracy: 0.9667 - val_loss: 0.3210 - val_accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.2416 - accuracy: 0.9467 - val_loss: 0.2996 - val_accuracy: 0.8973\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2171 - accuracy: 0.9733 - val_loss: 0.2919 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.2169 - accuracy: 0.9711 - val_loss: 0.2778 - val_accuracy: 0.9196\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.2137 - accuracy: 0.9733 - val_loss: 0.3309 - val_accuracy: 0.8839\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2009 - accuracy: 0.9800 - val_loss: 0.2686 - val_accuracy: 0.9241\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2043 - accuracy: 0.9756 - val_loss: 0.2787 - val_accuracy: 0.9196\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1961 - accuracy: 0.9778 - val_loss: 0.2938 - val_accuracy: 0.9107\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2023 - accuracy: 0.9711 - val_loss: 0.3097 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd76d6a55f8>"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# train \n",
    "model.fit_generator(\n",
    "    train_set, # data to train, a format of (X, y)\n",
    "    steps_per_epoch=len(train_set), # The number of batch iterations before a training epoch is considered finished. Ignore if whole data is load, in our case, we need this in order to iterate over batches; hence make sure that generator can generate at least: steps_per_epoch * epochs batches\n",
    "    epochs=50, # number of epochs, i.e number of time that iteration of updating weights goes\n",
    "    validation_data=test_set, # validation\n",
    "    validation_steps=len(test_set)\n",
    ")"
   ]
  }
 ]
}